"use strict";(self.webpackChunkphysical_ai_humanoid_robotics_q2=self.webpackChunkphysical_ai_humanoid_robotics_q2||[]).push([[4231],{5271(e,n,s){s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>l,toc:()=>c});const l=JSON.parse('{"id":"chapters/embodied-ai","title":"Chapter 1 \u2014 Physical AI / Embodied Intelligence","description":"Learning Objectives","source":"@site/docs/chapters/01-embodied-ai.md","sourceDirName":"chapters","slug":"/chapters/embodied-ai","permalink":"/hackathon1/chapters/embodied-ai","draft":false,"unlisted":false,"editUrl":"https://github.com/mohammadfaisalpirzada/hackathon1/edit/main/docs/chapters/01-embodied-ai.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Chapter 1 \u2014 Physical AI / Embodied Intelligence"},"sidebar":"tutorialSidebar","previous":{"title":"Setup: Ubuntu 22.04 + ROS 2 Humble + Simulation","permalink":"/hackathon1/course-setup"},"next":{"title":"Chapter 2 \u2014 ROS 2 Fundamentals (Nodes, Topics, Services, Actions)","permalink":"/hackathon1/chapters/ros2-fundamentals"}}');var i=s(4848),t=s(8453);const r={title:"Chapter 1 \u2014 Physical AI / Embodied Intelligence"},a="Chapter 1 - Physical AI / Embodied Intelligence",o={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Key Terms",id:"key-terms",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Concepts",id:"concepts",level:2},{value:"The \u201cagent loop\u201d (why robots are different)",id:"the-agent-loop-why-robots-are-different",level:3},{value:"What counts as \u201cPhysical AI\u201d in this course",id:"what-counts-as-physical-ai-in-this-course",level:3},{value:"Hands-on Lab: closed-loop control with <code>turtlesim</code> (ROS 2 Python)",id:"hands-on-lab-closed-loop-control-with-turtlesim-ros-2-python",level:2},{value:"Lab Deliverable",id:"lab-deliverable",level:2},{value:"Assessment Item",id:"assessment-item",level:2},{value:"1) Start turtlesim",id:"1-start-turtlesim",level:3},{value:"2) Create a workspace package",id:"2-create-a-workspace-package",level:3},{value:"3) Add a goal-seeking controller node",id:"3-add-a-goal-seeking-controller-node",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Quick Quiz",id:"quick-quiz",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"chapter-1---physical-ai--embodied-intelligence",children:"Chapter 1 - Physical AI / Embodied Intelligence"})}),"\n",(0,i.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Explain the closed-loop \u201cagent loop\u201d and why feedback is required for control."}),"\n",(0,i.jsx)(n.li,{children:"Implement a simple ROS 2 controller that uses state feedback to reach a goal."}),"\n",(0,i.jsx)(n.li,{children:"Identify how latency, blocking callbacks, and safety constraints affect robot behavior."}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"key-terms",children:"Key Terms"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Physical AI, embodied intelligence, closed-loop control, feedback, latency budget, safety constraint"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Completed ",(0,i.jsx)(n.code,{children:"Setup"})," and can run ",(0,i.jsx)(n.code,{children:"ros2"})," commands."]}),"\n",(0,i.jsx)(n.li,{children:"Installed turtlesim:"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo apt update\nsudo apt install -y ros-humble-turtlesim\n"})}),"\n",(0,i.jsx)(n.h2,{id:"concepts",children:"Concepts"}),"\n",(0,i.jsx)(n.h3,{id:"the-agent-loop-why-robots-are-different",children:"The \u201cagent loop\u201d (why robots are different)"}),"\n",(0,i.jsx)(n.p,{children:"In robotics, your model is part of a closed loop:"}),"\n",(0,i.jsx)(n.mermaid,{value:"flowchart LR\n  World --\x3e|sensors| Perception\n  Perception --\x3e State\n  State --\x3e|goal+constraints| Policy\n  Policy --\x3e|actions| Control\n  Control --\x3e|actuators| World"}),"\n",(0,i.jsx)(n.p,{children:"Key implications:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Latency matters"}),": a correct decision that arrives late is wrong."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Feedback matters"}),": you can\u2019t \u201cbatch evaluate\u201d; you must observe \u2192 act \u2192 observe."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Safety matters"}),": you need constraints and predictable failure modes."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"what-counts-as-physical-ai-in-this-course",children:"What counts as \u201cPhysical AI\u201d in this course"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Reactive controllers (good baseline)."}),"\n",(0,i.jsx)(n.li,{children:"Classical planning + control (still required)."}),"\n",(0,i.jsx)(n.li,{children:"Learned components (perception, behavior priors)."}),"\n",(0,i.jsx)(n.li,{children:"\u201cVLA\u201d stacks: speech/LLM planning feeding structured robot actions."}),"\n"]}),"\n",(0,i.jsxs)(n.h2,{id:"hands-on-lab-closed-loop-control-with-turtlesim-ros-2-python",children:["Hands-on Lab: closed-loop control with ",(0,i.jsx)(n.code,{children:"turtlesim"})," (ROS 2 Python)"]}),"\n",(0,i.jsx)(n.p,{children:'Goal: write a tiny ROS 2 "agent" that drives the turtle to a goal position using feedback.'}),"\n",(0,i.jsx)(n.h2,{id:"lab-deliverable",children:"Lab Deliverable"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["A runnable node ",(0,i.jsx)(n.code,{children:"q2_agent/goal_seek.py"})," that reaches a commanded goal (within a tolerance) using ",(0,i.jsx)(n.code,{children:"/turtle1/pose"})," feedback and publishes ",(0,i.jsx)(n.code,{children:"/turtle1/cmd_vel"}),"."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"assessment-item",children:"Assessment Item"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Demonstration check: run the node to reach two different goals and explain (briefly) what state is observed and what action is published."}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"1-start-turtlesim",children:"1) Start turtlesim"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Terminal A\nsource /opt/ros/humble/setup.bash\nros2 run turtlesim turtlesim_node\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Terminal B\nsource /opt/ros/humble/setup.bash\nros2 run turtlesim turtle_teleop_key\n"})}),"\n",(0,i.jsx)(n.p,{children:"Confirm topics:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 topic list | rg turtlesim\nros2 topic echo /turtle1/pose --once\n"})}),"\n",(0,i.jsx)(n.h3,{id:"2-create-a-workspace-package",children:"2) Create a workspace package"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"mkdir -p ~/q2_ws/src\ncd ~/q2_ws/src\nros2 pkg create q2_agent --build-type ament_python --dependencies rclpy geometry_msgs turtlesim\n"})}),"\n",(0,i.jsx)(n.h3,{id:"3-add-a-goal-seeking-controller-node",children:"3) Add a goal-seeking controller node"}),"\n",(0,i.jsxs)(n.p,{children:["Create ",(0,i.jsx)(n.code,{children:"~/q2_ws/src/q2_agent/q2_agent/goal_seek.py"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import math\n\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist\nfrom turtlesim.msg import Pose\n\n\nclass GoalSeek(Node):\n    def __init__(self) -> None:\n        super().__init__("goal_seek")\n        self.goal_x = float(self.declare_parameter("goal_x", 8.0).value)\n        self.goal_y = float(self.declare_parameter("goal_y", 8.0).value)\n\n        self.pose: Pose | None = None\n        self.sub = self.create_subscription(Pose, "/turtle1/pose", self.on_pose, 10)\n        self.pub = self.create_publisher(Twist, "/turtle1/cmd_vel", 10)\n        self.timer = self.create_timer(0.05, self.on_tick)  # 20 Hz\n\n    def on_pose(self, msg: Pose) -> None:\n        self.pose = msg\n\n    def on_tick(self) -> None:\n        if self.pose is None:\n            return\n\n        dx = self.goal_x - self.pose.x\n        dy = self.goal_y - self.pose.y\n        distance = math.hypot(dx, dy)\n        goal_theta = math.atan2(dy, dx)\n        heading_error = self._wrap(goal_theta - self.pose.theta)\n\n        cmd = Twist()\n        cmd.angular.z = 4.0 * heading_error\n        cmd.linear.x = 1.5 * distance if abs(heading_error) < 0.7 else 0.0\n        self.pub.publish(cmd)\n\n        if distance < 0.15:\n            self.get_logger().info("Goal reached")\n            self.pub.publish(Twist())\n            rclpy.shutdown()\n\n    @staticmethod\n    def _wrap(angle: float) -> float:\n        while angle > math.pi:\n            angle -= 2 * math.pi\n        while angle < -math.pi:\n            angle += 2 * math.pi\n        return angle\n\n\ndef main() -> None:\n    rclpy.init()\n    node = GoalSeek()\n    rclpy.spin(node)\n\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,i.jsxs)(n.p,{children:["Register the entry point in ",(0,i.jsx)(n.code,{children:"~/q2_ws/src/q2_agent/setup.py"})," (add to ",(0,i.jsx)(n.code,{children:"console_scripts"}),"):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'entry_points={\n    "console_scripts": [\n        "goal_seek = q2_agent.goal_seek:main",\n    ],\n},\n'})}),"\n",(0,i.jsx)(n.p,{children:"Build:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cd ~/q2_ws\ncolcon build --symlink-install\nsource ~/q2_ws/install/setup.bash\n"})}),"\n",(0,i.jsx)(n.p,{children:"Run:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 run q2_agent goal_seek --ros-args -p goal_x:=2.0 -p goal_y:=9.0\n"})}),"\n",(0,i.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Node exits immediately","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["You never received ",(0,i.jsx)(n.code,{children:"/turtle1/pose"}),". Ensure ",(0,i.jsx)(n.code,{children:"turtlesim_node"})," is running."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Turtle spins wildly","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Heading gain too high. Lower ",(0,i.jsx)(n.code,{children:"cmd.angular.z"})," multiplier (e.g., ",(0,i.jsx)(n.code,{children:"2.0 * heading_error"}),")."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Turtle overshoots the goal","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Add a max speed clamp, or reduce linear gain."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"quick-quiz",children:"Quick Quiz"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Why is latency often more important than accuracy in robot control loops?"}),"\n",(0,i.jsx)(n.li,{children:"In the lab, what variable is the \u201cstate estimate\u201d?"}),"\n",(0,i.jsx)(n.li,{children:"What happens if you publish control commands without subscribing to feedback?"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453(e,n,s){s.d(n,{R:()=>r,x:()=>a});var l=s(6540);const i={},t=l.createContext(i);function r(e){const n=l.useContext(t);return l.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),l.createElement(t.Provider,{value:n},e.children)}}}]);